{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract matrices and predictors for fMRI analyses, and value inference analyses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from MonsterPrior import MonsterPrior\n",
    "from importlib import reload\n",
    "from pathlib import Path\n",
    "from SuccessorRepresentation import SuccessorRepresentation\n",
    "from GraphGP import LaplacianGP\n",
    "import copy\n",
    "import time\n",
    "\n",
    "### Open pickled files\n",
    "\n",
    "with open('transitions.pickle', 'rb') as handle:\n",
    "    transition_dict = pickle.load(handle)\n",
    "\n",
    "\n",
    "with open('path_integration_kernels.pickle', 'rb') as handle:\n",
    "    estimated_euclidean_kernels = pickle.load(handle)\n",
    "\n",
    "with open('path_integration_monster_locations.pickle', 'rb') as handle:\n",
    "    PI_dict = pickle.load(handle)\n",
    "\n",
    "\n",
    "### Unpack and process these things into a dictionary which we we'll during the analysis\n",
    "\n",
    "\n",
    "\n",
    "### Preamble - set some variables, create dataframes etc, nothing crazy\n",
    "df = pd.read_csv('choice_data.csv')\n",
    "\n",
    "\n",
    "subj = np.array(df[\"subj\"])\n",
    "op1 = np.array(df[\"option1\"])\n",
    "op2 = np.array(df[\"option2\"])\n",
    "choices = np.array(df[\"chosen_object\"])\n",
    "contexts = np.array(df[\"map\"])\n",
    "decisions = np.array(df[\"decision\"])\n",
    "\n",
    "# subtract 1 from these vectors so that the monster id becomes indices\n",
    "op1 -= 1\n",
    "op2 -= 1\n",
    "choices -= 1\n",
    "decisions -= 1\n",
    "\n",
    "rewards = np.array(df[\"chosen_value\"])\n",
    "\n",
    "states = np.arange(0, 12)\n",
    "\n",
    "###############################################\n",
    "### define the model value estimation functions,\n",
    "### as well as some other helper functions\n",
    "###############################################\n",
    "\n",
    "\n",
    "\n",
    "def estimate_successor_model(SR, R, option_indices):\n",
    "    \n",
    "    V = SR @ R\n",
    "    V_i = V[option_indices]\n",
    "    return V_i[0] - V_i[1]\n",
    "\n",
    "def estimate_euclidean_model(K, R, training_idx, option_indices):\n",
    "    \n",
    "    gp = LaplacianGP()\n",
    "    gp.set_training_data(training_idx, R)\n",
    "    gp.set_covariance(euclidean_covariance)\n",
    "    mu = gp.mean()\n",
    "    options = mu[option_indices]\n",
    "    return options[0] - options[1]\n",
    "\n",
    "\n",
    "def estimate_subjective_euclidean_model(K, R, training_idx, option_indices):\n",
    "    gp = LaplacianGP()\n",
    "    gp.set_training_data(training_idx, R)\n",
    "    gp.set_covariance(K)\n",
    "    mu = gp.mean()\n",
    "    options = mu[option_indices]\n",
    "    return options[0] - options[1]\n",
    "\n",
    "def estimate_GP(K, R, training_idx, option_indices):\n",
    "    gp = LaplacianGP()\n",
    "    gp.set_training_data(training_idx, R)\n",
    "    gp.set_covariance(K)\n",
    "    mu = gp.mean()\n",
    "    options = mu[option_indices]\n",
    "    return [options[0], options[1]]\n",
    "    \n",
    "def estimate_GP_full(K, R, training_idx):\n",
    "    gp = LaplacianGP()\n",
    "    gp.set_training_data(training_idx, R)\n",
    "    gp.set_covariance(K)\n",
    "    mu = gp.mean()\n",
    "    return mu\n",
    "\n",
    "def optimize_gp(X, training_idx, y, option_indices):\n",
    "    gp = LaplacianGP()\n",
    "    gp.set_training_data(training_idx, y)\n",
    "    X_train = X[training_idx]\n",
    "    K_optimal, l, n = gp.minimize_nll(X, X_train)\n",
    "\n",
    "    gp.set_covariance(K_optimal)\n",
    "    mu = gp.mean()\n",
    "    options = mu[option_indices]\n",
    "    return options[0] - options[1]    \n",
    "\n",
    "\n",
    "def weigh_kernels(k1, k2, training_idx, y):\n",
    "    gp1 = LaplacianGP()\n",
    "    gp1.set_training_data(training_idx, y)\n",
    "    gp1.set_covariance(k1)\n",
    "    nll1 = gp1.evaluate_nll()\n",
    "    \n",
    "    gp2 = LaplacianGP()\n",
    "    gp2.set_training_data(training_idx, y)\n",
    "    gp2.set_covariance(k2)\n",
    "    nll2 = gp2.evaluate_nll()\n",
    "    \n",
    "    k1_ml = np.exp(-nll1)\n",
    "    k2_ml = np.exp(-nll2)\n",
    "\n",
    "    if (k1_ml + k2_ml) != 0:\n",
    "        p1 = k1_ml / (k1_ml + k2_ml)\n",
    "        p2 = 1-p1\n",
    "    else:\n",
    "        p1 = 0.5\n",
    "        p2 = 0.5\n",
    "    return p1, p2\n",
    "\n",
    "\n",
    "def get_ml(k1, k2, training_idx, y):\n",
    "    gp1 = LaplacianGP()\n",
    "    gp1.set_training_data(training_idx, y)\n",
    "    gp1.set_covariance(k1)\n",
    "    nll1 = gp1.evaluate_nll()\n",
    "    \n",
    "    gp2 = LaplacianGP()\n",
    "    gp2.set_training_data(training_idx, y)\n",
    "    gp2.set_covariance(k2)\n",
    "    nll2 = gp2.evaluate_nll()\n",
    "    \n",
    "    k1_ml = np.exp(-nll1)\n",
    "    k2_ml = np.exp(-nll2)\n",
    "\n",
    "\n",
    "    return k1_ml, k2_ml\n",
    "\n",
    "\n",
    "def estimate_transition_matrix(M, gamma, lmbd = 0.0000001):\n",
    "\n",
    "    I = np.eye(len(M))\n",
    "    jitter = lmbd * np.eye(len(M))\n",
    "\n",
    "\n",
    "    T = (np.linalg.inv(M + jitter) - I) / -gamma\n",
    "    return T\n",
    "\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x)/np.sum(np.exp(x))\n",
    "\n",
    "def SR_softmax(graph, rewards):\n",
    "    nodes = list(graph.nodes)\n",
    "    T = np.zeros((len(nodes),len(nodes) ))\n",
    "    for i, node in enumerate(nodes):\n",
    "        p = np.zeros(len(nodes))\n",
    "        adj = np.array(list(graph.neighbors(node)))\n",
    "        r_adj = rewards[adj]\n",
    "        s_max = softmax(r_adj)\n",
    "        p[ajd] = s_max\n",
    "        T[i] = p\n",
    "\n",
    "    T = make_symmetric(T)\n",
    "    L = np.eye(len(nodes)) - T\n",
    "    return L\n",
    "    \n",
    "\n",
    "def SR_bayesian(graph, prior_T, rewards):\n",
    "    nodes = list(graph.nodes)\n",
    "    T = np.zeros((len(nodes),len(nodes) ))\n",
    "    for i, node in enumerate(nodes):\n",
    "        p = np.zeros(len(nodes))\n",
    "        adj = np.array(list(graph.neighbors(node)))\n",
    "        r_adj = rewards[adj]\n",
    "        s_max = softmax(r_adj)\n",
    "        prior = prior_T[i]\n",
    "        prior /= np.sum(prior)\n",
    "        p[ajd] = s_max\n",
    "        p = (p*prior)/np.sum(p*prior)\n",
    "        T[i] = p\n",
    "\n",
    "    T = make_symmetric(T)\n",
    "    L = np.eye(len(nodes)) - T\n",
    "    return L\n",
    "\n",
    "\n",
    "def make_symmetric(T):\n",
    "    T_upper = np.triu(T)\n",
    "    T_lower = np.tril(T)\n",
    "\n",
    "    T_upperT = T_upper.T\n",
    "    T_lowerT = T_lower.T\n",
    "\n",
    "    T_upper = np.maximum(T_upper, T_lowerT)\n",
    "    T_lower = np.maximum(T_upperT, T_lower)\n",
    "    T = T_upper + T_lower\n",
    "    return T\n",
    "\n",
    "\n",
    "def estimate_laplacian(M, gamma, lmbd=0.000001, plot=False):\n",
    "    T = estimate_transition_matrix(M, gamma)\n",
    "    np.fill_diagonal(T, 0)\n",
    "    T[T<0] = 0\n",
    "    \n",
    "    \n",
    "    ## make matrices symmetric again!\n",
    "    T_upper = np.triu(T)\n",
    "    T_lower = np.tril(T)\n",
    "\n",
    "    T_upperT = T_upper.T\n",
    "    T_lowerT = T_lower.T\n",
    "\n",
    "    T_upper = np.maximum(T_upper, T_lowerT)\n",
    "    T_lower = np.maximum(T_upperT, T_lower)\n",
    "    T = T_upper + T_lower\n",
    "\n",
    "    ###\n",
    "    if plot:\n",
    "        construct_graph_from_T(T)\n",
    "    ###\n",
    "    \n",
    "    L = np.eye(len(T)) - T\n",
    " \n",
    "    return L\n",
    "\n",
    "def remove_outliers(array):\n",
    "    idx = np.where(np.abs(array - np.mean(array)) < 2 * np.std(array))\n",
    "    return idx\n",
    "\n",
    "\n",
    "def construct_graph_from_T(T):\n",
    "    A = T.copy()\n",
    "    A[A>0] = 1\n",
    "    g = nx.from_numpy_matrix(T)\n",
    "    edges = list(g.edges)\n",
    "    weights = []\n",
    "    for e in edges:\n",
    "        w = T[e[0], e[1]]\n",
    "\n",
    "        # for smoother edge coloring, we scale the weights up a bit\n",
    "        if w < 0.5:\n",
    "            w+=0.1\n",
    "        weights.append(w)\n",
    "\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    plt.title(\"\")\n",
    "    nx.draw(g, pos, with_labels=True, edgelist = edges,  width=np.array(weights)*6)\n",
    "    plt.show()\n",
    "#    plt.savefig(f\"figures/exploration_paths/graphs/{subj_id}.{graph_save_format}\")\n",
    "#    plt.show()\n",
    "    \n",
    "#        nx.draw(g, pos, with_labels=True, edgelist = edges, edge_color = weights,edge_cmap=plt.cm.Greys, width=np.array(weights)*4)\n",
    "#        plt.colorbar()\n",
    "#        plt.show()\n",
    "    \n",
    "    \n",
    "def estimate_sr_graph_model(sr_graph, R, training_idx, option_indices, lengthscale):\n",
    "    \n",
    "    gp = LaplacianGP()\n",
    "    gp.train(sr_graph, training_idx, R, alpha=lengthscale)\n",
    "\n",
    "    mu = gp.mean()\n",
    "    options = mu[option_indices]\n",
    "    return options[0] - options[1]\n",
    "\n",
    "\n",
    "def estimate_graph_model(graph, R, training_idx, option_indices, lengthscale):\n",
    "\n",
    "    gp = LaplacianGP()\n",
    "    gp.train(graph, training_idx, R, alpha=lengthscale)\n",
    "    mu = gp.mean()\n",
    "\n",
    "    options = mu[option_indices]\n",
    "    return options[0] - options[1]\n",
    "\n",
    "def RBF(X1, X2, var = 1, l = 1):\n",
    "        \n",
    "    sqdist = np.sum(X1**2, 1).reshape(-1, 1) + np.sum(X2**2, 1) - 2 * np.dot(X1, X2.T)\n",
    "    return var**2 * np.exp(-0.5 / l**2 * sqdist)\n",
    "\n",
    "\n",
    "#### Unpack data\n",
    "\n",
    "tbt_weights = pd.read_csv(\"tBt_euc_w.csv\").values\n",
    "\n",
    "# the alternative effects\n",
    "effects_df = pd.read_csv(\"effects_and_weights.csv\")\n",
    "m_rewards = np.array(effects_df[\"m.rewards\"])\n",
    "\n",
    "final_weights_euclidean = np.array(effects_df[\"w.euc\"])\n",
    "trial_weights = np.array(effects_df[\"trialw\"])\n",
    "\n",
    "per_trial_df = pd.read_csv(\"per_trial_df.csv\")\n",
    "\n",
    "## note that there's a typo in \"moster_rewards\"\n",
    "monster_rewards = pd.read_csv(\"moster_rewards.csv\")\n",
    "\n",
    "MR_1 = np.array(monster_rewards[\"ctx1\"])\n",
    "MR_2 = np.array(monster_rewards[\"ctx2\"])\n",
    "\n",
    "reward_dict = {1: MR_1, 2: MR_2}\n",
    "\n",
    "sr_diffusion = 1\n",
    "\n",
    "\n",
    "\n",
    "### create matrices with predictions and RPEs\n",
    "\n",
    "num_trials = 100\n",
    "num_participants = len(np.unique(subj))\n",
    "\n",
    "SR_GP_preds_chosen = np.zeros((num_participants, num_trials))\n",
    "SR_GP_preds_unchosen = np.zeros((num_participants, num_trials))\n",
    "SR_GP_RPE = np.zeros((num_participants, num_trials))\n",
    "\n",
    "euc_GP_preds_chosen = np.zeros((num_participants, num_trials))\n",
    "euc_GP_preds_unchosen = np.zeros((num_participants, num_trials))\n",
    "euc_GP_RPE = np.zeros((num_participants, num_trials))\n",
    "\n",
    "rich_euc_GP_preds_chosen = np.zeros((num_participants, num_trials))\n",
    "rich_euc_GP_preds_unchosen = np.zeros((num_participants, num_trials))\n",
    "rich_euc_GP_RPE = np.zeros((num_participants, num_trials))\n",
    "\n",
    "\n",
    "comp_preds_chosen = np.zeros((num_participants, num_trials))\n",
    "comp_preds_unchosen = np.zeros((num_participants, num_trials))\n",
    "comp_RPE = np.zeros((num_participants, num_trials))\n",
    "\n",
    "###\n",
    "\n",
    "\n",
    "last_subj = -1  # make this an id so that the first participant isn't identical to this one\n",
    "subj_counter = -1\n",
    "\n",
    "\n",
    "### this variable controls whether the data used for fmri analysis should be saved\n",
    "save_data = True\n",
    "###########\n",
    "\n",
    "\n",
    "\n",
    "predicted_values_ctx1 = np.zeros((num_participants, 12))\n",
    "predicted_values_ctx2 = np.zeros((num_participants, 12))\n",
    "\n",
    "\n",
    "comp_predicted_values_ctx1 = np.zeros((num_participants, 12))\n",
    "comp_predicted_values_ctx2 = np.zeros((num_participants, 12))\n",
    "\n",
    "\n",
    "euc_predicted_values_ctx1 = np.zeros((num_participants, 12))\n",
    "euc_predicted_values_ctx2 = np.zeros((num_participants, 12))\n",
    "\n",
    "sr_predicted_values_ctx1 = np.zeros((num_participants, 12))\n",
    "sr_predicted_values_ctx2 = np.zeros((num_participants, 12))\n",
    "\n",
    "MT_predicted_values_ctx1 = np.zeros((num_participants, 12))\n",
    "MT_predicted_values_ctx2 = np.zeros((num_participants, 12))\n",
    "\n",
    "\n",
    "\n",
    "## initialize monster locations\n",
    "mp = MonsterPrior(lengthscale=0.1)\n",
    "monster_loc = mp.pos\n",
    "pos = {}\n",
    "for i in range(len(monster_loc)):\n",
    "    pos[i] = (monster_loc[i, 0], monster_loc[i, 1])\n",
    "\n",
    "#### set this variable to True to save simulation/graphs/control data\n",
    "save_simulation_data = False\n",
    "save_control = True\n",
    "save_sr_graphs = False\n",
    "graph_save_format =\"eps\"\n",
    "\n",
    "\n",
    "#############################\n",
    "\n",
    "sr_rewards = np.zeros((num_participants, num_trials))\n",
    "sr_gp_rewards = np.zeros((num_participants, num_trials))\n",
    "comp_rewards = np.zeros((num_participants, num_trials))\n",
    "op_gp_rewards = np.zeros((num_participants, num_trials))\n",
    "euc_rewards = np.zeros((num_participants, num_trials))\n",
    "\n",
    "\n",
    "### here we initialize some arrays containing single predictors, which we use as control models\n",
    "\n",
    "comp_random = np.zeros(len(subj))\n",
    "mean_tracker = np.zeros(len(subj))\n",
    "\n",
    "all_subjects = np.unique(subj)\n",
    "\n",
    "### arrays used for computing marginal likelhoods and weights\n",
    "comp_w = np.zeros(4800)  # compositional weights, estimated with log marginal likelihoods\n",
    "marginal_euc = np.zeros(4800)\n",
    "marginal_sr = np.zeros(4800)\n",
    "\n",
    "### an array containing a 1 for the trials where subjects have already seen the values of both monsters:\n",
    "true_diff = np.zeros(4800)\n",
    "observed_both = np.zeros(4800)\n",
    "chosen_monster_visits = np.zeros(4800)\n",
    "unchosen_monster_visits = np.zeros(4800)\n",
    "\n",
    "\n",
    "### Start loop\n",
    "\n",
    "for i, subj_id in enumerate(subj):\n",
    "    current_context = contexts[i]\n",
    "    if subj_id != last_subj:\n",
    "\n",
    "        subj_counter += 1\n",
    "        trial_counter = 0\n",
    "        ### set hyperparameters\n",
    "\n",
    "        lengthscale = 1.24\n",
    "        compositional_lengthscale = 2.05\n",
    "        \n",
    "        loc = PI_dict[subj_id]\n",
    "\n",
    "        learning_rate= 0.4125\n",
    "        learning_rate_compositional = 0.01\n",
    "\n",
    "        lengthscale = 1.24\n",
    "        weight_euclidean = final_weights_euclidean[subj_counter]\n",
    "        \n",
    "        \n",
    "\n",
    "        context_dict = {}\n",
    "        context_dict[1] ={\"training_idx\": [], \"rewards\": [], \"state_rewards\" : np.zeros(len(np.arange(12)))} \n",
    "        context_dict[2] = {\"training_idx\": [], \"rewards\": [], \"state_rewards\" : np.zeros(len(np.arange(12)))} \n",
    "\n",
    "        ### SR\n",
    "\n",
    "        seq_list = []\n",
    "        seq_len = 0\n",
    "\n",
    "        for k, (run, seq) in enumerate(transition_dict[subj_id].items()):\n",
    "            \n",
    "                seq_ = copy.deepcopy(seq)\n",
    "                seq_ -=1\n",
    "\n",
    "                seq_list.append(seq_)\n",
    "                seq_len += len(seq_)\n",
    "\n",
    "        sr_model = SuccessorRepresentation(states, seq_list, alpha=learning_rate)\n",
    "        SR1 = sr_model.get_SR()\n",
    "\n",
    "        SRL = estimate_laplacian(SR1, gamma = sr_model.gamma, plot=save_sr_graphs)\n",
    "\n",
    "        \n",
    "       \n",
    "        SR_kernel = scipy.linalg.expm(-sr_diffusion*SRL)\n",
    "\n",
    "\n",
    "        #### now for the compositional kernel\n",
    "        #### we don't save this one\n",
    "        sr_model = SuccessorRepresentation(states, seq_list, alpha=learning_rate_compositional)\n",
    "        SR2 = sr_model.get_SR()\n",
    "\n",
    "        SRL = estimate_laplacian(SR2, gamma = sr_model.gamma, plot=False)\n",
    "\n",
    "       \n",
    "        SR_kernel_comp = scipy.linalg.expm(-sr_diffusion*SRL)\n",
    "\n",
    "\n",
    "        ### Euclidean\n",
    "\n",
    "        estimated_euclidean_kernel = RBF(loc, loc, l=lengthscale)\n",
    "        estimated_euclidean_kernel_comp = RBF(loc, loc, l=compositional_lengthscale)\n",
    "\n",
    "\n",
    "        ### Euclidean with larger lengthscale to avoid problems for the glms\n",
    "        estimated_euclidean_kernel_rich = RBF(loc, loc, l=1)\n",
    "\n",
    "        ##### weighted\n",
    "        comp_kernel = (estimated_euclidean_kernel_comp + SR_kernel_comp)/2\n",
    "\n",
    "        if save_data:\n",
    "            Path(f\"fmri/matrices/{subj_id}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            SR_df = pd.DataFrame(SR1)\n",
    "            SR_df.to_csv(f\"fmri/matrices/{subj_id}/SR_matrix.csv\", index=False, header=False)\n",
    "            \n",
    "#             SR_kernel_df = pd.DataFrame(SR_kernel) ## save the temporal kernel used in the compositional model\n",
    "#             SR_kernel_df.to_csv(f\"fmri/matrices/{subj_id}/SR_kernel_matrix.csv\", index=False, header=False)\n",
    "\n",
    "            SR_kernel_df = pd.DataFrame(SR_kernel_comp) ## save the temporal kernel used in the compositional model\n",
    "            SR_kernel_df.to_csv(f\"fmri/matrices/{subj_id}/SR_kernel_matrix.csv\", index=False, header=False)\n",
    "\n",
    "            euclidean_kernel_df = pd.DataFrame(estimated_euclidean_kernel_comp)\n",
    "            euclidean_kernel_df.to_csv(f\"fmri/matrices/{subj_id}/euclidean_kernel_matrix.csv\", index=False, header=False)\n",
    "\n",
    "            rich_euclidean_df = pd.DataFrame(estimated_euclidean_kernel_rich)\n",
    "            rich_euclidean_df.to_csv(f\"fmri/matrices/{subj_id}/rich_euclidean_kernel_matrix.csv\", index=False, header=False)\n",
    "\n",
    "            weighted_comp_kernel_df = pd.DataFrame(comp_kernel)\n",
    "            weighted_comp_kernel_df.to_csv(f\"fmri/matrices/{subj_id}/weighted_comp_kernel_matrix.csv\", index=False, header=False)\n",
    "\n",
    "\n",
    "\n",
    "        ### add observations for this context\n",
    "        options = [op1[i], op2[i]]\n",
    "        choice = choices[i]\n",
    "        reward = rewards[i]\n",
    "\n",
    "        decision = decisions[i]\n",
    "        unchosen = 1 - decision\n",
    "        \n",
    "        chosen_monster_visits[i] = SR1[options[decision], options[decision]]\n",
    "        unchosen_monster_visits[i] = SR1[options[unchosen], options[unchosen]]\n",
    "\n",
    "        true_diff_i = reward_dict[current_context][op1[i]] - reward_dict[current_context][op2[i]]\n",
    "        true_diff[i] = true_diff_i\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        context_dict[current_context][\"training_idx\"].append(choice)\n",
    "        context_dict[current_context][\"rewards\"].append(reward)\n",
    "        context_dict[current_context][\"state_rewards\"][choice] = reward\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        SR_GP_preds_chosen[subj_counter, trial_counter] = 0\n",
    "        SR_GP_preds_unchosen[subj_counter, trial_counter] = 0\n",
    "        SR_GP_RPE[subj_counter, trial_counter] = (-reward)\n",
    "\n",
    "        euc_GP_preds_chosen[subj_counter, trial_counter] = 0\n",
    "        euc_GP_preds_unchosen[subj_counter, trial_counter] = 0\n",
    "        euc_GP_RPE[subj_counter, trial_counter] = (-reward)\n",
    "\n",
    "        rich_euc_GP_preds_chosen[subj_counter, trial_counter] = 0\n",
    "        rich_euc_GP_preds_unchosen[subj_counter, trial_counter] = 0\n",
    "        rich_euc_GP_RPE[subj_counter, trial_counter] = -reward\n",
    "\n",
    "\n",
    "        comp_preds_chosen[subj_counter, trial_counter] = 0\n",
    "        comp_preds_unchosen[subj_counter, trial_counter] = 0\n",
    "        comp_RPE[subj_counter, trial_counter] = (-reward)\n",
    "\n",
    "\n",
    "        ## set the last subj_id to the current one\n",
    "        last_subj = subj_id\n",
    "        trial_counter += 1\n",
    "        comp_w[i] = 0.5\n",
    "\n",
    "\n",
    "    elif len(context_dict[current_context][\"rewards\"]) == 0:  # check if participant has been able to make any observations in this context yet \n",
    "        # if not then let choice be random, and store observations into context dict\n",
    "\n",
    "        options = [op1[i], op2[i]]\n",
    "        choice = choices[i]\n",
    "        reward = rewards[i]\n",
    "\n",
    "        decision = decisions[i]\n",
    "        unchosen = 1 - decision\n",
    "        \n",
    "        chosen_monster_visits[i] = SR1[options[decision], options[decision]]\n",
    "        unchosen_monster_visits[i] = SR1[options[unchosen], options[unchosen]]\n",
    "\n",
    "\n",
    "        true_diff_i = reward_dict[current_context][op1[i]] - reward_dict[current_context][op2[i]]\n",
    "        true_diff[i] = true_diff_i\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        context_dict[current_context][\"training_idx\"].append(choice)\n",
    "        context_dict[current_context][\"rewards\"].append(reward)\n",
    "        context_dict[current_context][\"state_rewards\"][choice] = reward\n",
    "\n",
    "\n",
    "        SR_GP_preds_chosen[subj_counter, trial_counter] = 0\n",
    "        SR_GP_preds_unchosen[subj_counter, trial_counter] = 0\n",
    "        SR_GP_RPE[subj_counter, trial_counter] = (-reward)\n",
    "\n",
    "        euc_GP_preds_chosen[subj_counter, trial_counter] = 0\n",
    "        euc_GP_preds_unchosen[subj_counter, trial_counter] = 0\n",
    "        euc_GP_RPE[subj_counter, trial_counter] = (-reward)\n",
    "\n",
    "        rich_euc_GP_preds_chosen[subj_counter, trial_counter] = 0\n",
    "        rich_euc_GP_preds_unchosen[subj_counter, trial_counter] = 0\n",
    "        rich_euc_GP_RPE[subj_counter, trial_counter] = -reward\n",
    "\n",
    "\n",
    "        comp_preds_chosen[subj_counter, trial_counter] = 0\n",
    "        comp_preds_unchosen[subj_counter, trial_counter] = 0\n",
    "        comp_RPE[subj_counter, trial_counter] = (-reward)\n",
    "\n",
    "        trial_counter += 1\n",
    "        comp_w[i] = 0.5\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        options = [op1[i], op2[i]]\n",
    "\n",
    "        choice = choices[i]\n",
    "        decision = decisions[i]\n",
    "        unchosen = 1 - decision\n",
    "        reward = rewards[i]\n",
    "\n",
    "\n",
    "        true_diff_i = reward_dict[current_context][op1[i]] - reward_dict[current_context][op2[i]]\n",
    "        true_diff[i] = true_diff_i\n",
    "        \n",
    "        chosen_monster_visits[i] = SR1[options[decision], options[decision]]\n",
    "        unchosen_monster_visits[i] = SR1[options[unchosen], options[unchosen]]\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        training_idx = context_dict[current_context][\"training_idx\"] # the training indices for the gps\n",
    "        R = copy.copy(context_dict[current_context][\"state_rewards\"]) # an array with rewards for each state for the SR. We copy so that it doesn't change when we normalize it\n",
    "        y = np.array(copy.copy(context_dict[current_context][\"rewards\"]))  # for use in the gp models. we copy this so we can normalize it and convert it into an array without messing with the original set of reward observations\n",
    "\n",
    "        y_prime = np.append(y, reward)\n",
    "\n",
    "        if y.std() != 0:\n",
    "            y = (y- y.mean())/y.std()\n",
    "            y_prime = (y_prime - y_prime.mean())/y_prime.std()\n",
    "\n",
    "        else:\n",
    "            y = (y - y.mean())\n",
    "            y_prime = (y_prime - y_prime.mean())\n",
    "\n",
    "        reward_normalized = y_prime[-1]\n",
    "\n",
    "        SR_GP_preds = estimate_GP(SR_kernel, y, training_idx, option_indices=options)\n",
    "        euclidean_preds = estimate_GP(estimated_euclidean_kernel, y, training_idx, option_indices=options)\n",
    "        rich_euclidean_preds = estimate_GP(estimated_euclidean_kernel_rich, y, training_idx, option_indices=options)\n",
    "        comp_preds = estimate_GP(comp_kernel, y, training_idx, option_indices=options)\n",
    "\n",
    "\n",
    "        ## alternative control models\n",
    "        MT_kernel = np.eye(12)\n",
    "        MT_preds = estimate_GP(MT_kernel, y, training_idx, option_indices=options)\n",
    "        MT_diff = MT_preds[0] - MT_preds[1]\n",
    "        \n",
    "        mean_tracker[i] = MT_diff\n",
    "\n",
    "        ## estimate log likelihood for SR and Euclidean\n",
    "        p_euc, p_sr = weigh_kernels(estimated_euclidean_kernel, SR_kernel, np.append(training_idx, [choice]), y_prime)\n",
    "        #ml_euc, ml_sr = get_ml(estimated_euclidean_kernel, SR_kernel, np.arraytraining_idx, np.array([reward_normalized]))\n",
    "        ml_euc, ml_sr = get_ml(estimated_euclidean_kernel, SR_kernel, np.append(training_idx, [choice]), y_prime)\n",
    "        comp_w[i] = p_euc\n",
    "        marginal_euc[i] = ml_euc\n",
    "        marginal_sr[i] = ml_sr\n",
    "\n",
    "        if (op1[i] in training_idx) and (op2[i] in training_idx):\n",
    "            observed_both[i] = 1\n",
    "\n",
    "        \n",
    "        SR_GP_preds_chosen[subj_counter, trial_counter] = SR_GP_preds[decision]\n",
    "        SR_GP_preds_unchosen[subj_counter, trial_counter] = SR_GP_preds[unchosen]\n",
    "        SR_GP_RPE[subj_counter, trial_counter] = (SR_GP_preds[decision] - reward_normalized)\n",
    "\n",
    "        euc_GP_preds_chosen[subj_counter, trial_counter] = euclidean_preds[decision]\n",
    "        euc_GP_preds_unchosen[subj_counter, trial_counter] = euclidean_preds[unchosen]\n",
    "        euc_GP_RPE[subj_counter, trial_counter] = (euclidean_preds[decision] - reward_normalized)\n",
    "\n",
    "        rich_euc_GP_preds_chosen[subj_counter, trial_counter] = rich_euclidean_preds[decision]\n",
    "        rich_euc_GP_preds_unchosen[subj_counter, trial_counter] = rich_euclidean_preds[unchosen]\n",
    "        rich_euc_GP_RPE[subj_counter, trial_counter] = rich_euclidean_preds[decision] - reward_normalized\n",
    "\n",
    "\n",
    "        comp_preds_chosen[subj_counter, trial_counter] = comp_preds[decision]\n",
    "        comp_preds_unchosen[subj_counter, trial_counter] = comp_preds[unchosen]\n",
    "        comp_RPE[subj_counter, trial_counter] = (comp_preds[decision] - reward_normalized)\n",
    "\n",
    "\n",
    "        ###  for all monsters\n",
    "        if trial_counter == 89 or trial_counter == 99:\n",
    "            ## get unnormalized values\n",
    "            y = np.array(copy.copy(context_dict[current_context][\"rewards\"]))\n",
    "            \n",
    "            full_comp_preds = estimate_GP_full(comp_kernel, y, training_idx)\n",
    "            full_euc_preds = estimate_GP_full(estimated_euclidean_kernel, y, training_idx)\n",
    "            full_sr_preds = estimate_GP_full(SR_kernel, y, training_idx)\n",
    "            full_MT_preds = estimate_GP_full(MT_kernel, y, training_idx)\n",
    "\n",
    "            if current_context == 1:\n",
    "\n",
    "\n",
    "                predicted_values_ctx1[subj_counter] = (full_comp_preds)\n",
    "\n",
    "                euc_predicted_values_ctx1[subj_counter] = (full_euc_preds)\n",
    "                sr_predicted_values_ctx1[subj_counter] = (full_sr_preds)\n",
    "                MT_predicted_values_ctx1[subj_counter] = full_MT_preds\n",
    "                \n",
    "            else:\n",
    "\n",
    "                predicted_values_ctx2[subj_counter] = (full_comp_preds)\n",
    "\n",
    "                euc_predicted_values_ctx2[subj_counter] = (full_euc_preds)\n",
    "                sr_predicted_values_ctx2[subj_counter] = (full_sr_preds)\n",
    "                MT_predicted_values_ctx2[subj_counter] = full_MT_preds\n",
    "\n",
    "\n",
    "\n",
    "        ### update arrays:\n",
    "        context_dict[current_context][\"training_idx\"].append(choice)\n",
    "        context_dict[current_context][\"rewards\"].append(reward)\n",
    "        context_dict[current_context][\"state_rewards\"][choice] = reward\n",
    "        \n",
    "        trial_counter += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Save data from control models\n",
    "if save_control:\n",
    "    MT_df = pd.DataFrame(mean_tracker)\n",
    "    MT_df.to_csv(\"param_fits/mean_tracker.csv\", index=False)\n",
    "\n",
    "    true_diff_df = pd.DataFrame(true_diff)\n",
    "    true_diff_df.to_csv(\"param_fits/true_diff.csv\", index=False)\n",
    "    observed_both_df = pd.DataFrame(observed_both)\n",
    "    observed_both_df.to_csv(\"param_fits/observed_both.csv\", index=False)\n",
    "    chosen_visits = pd.DataFrame(chosen_monster_visits)\n",
    "    chosen_visits.to_csv(\"param_fits/chosen_visits.csv\", index=False)\n",
    "    unchosen_visits = pd.DataFrame(unchosen_monster_visits)\n",
    "    unchosen_visits.to_csv(\"param_fits/unchosen_visits.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "### here are some functions for estimating and smoothing the weights, as well as saving the weight data\n",
    "def w_delta(w):\n",
    "    w_change = np.zeros(len(w))\n",
    "    for i in range(len(w) - 1):\n",
    "        if i != 0:\n",
    "            w_change[i] = w[i] - w[i-1]\n",
    "\n",
    "    return w_change\n",
    "\n",
    "\n",
    "def w_delta_smooth(w, n):\n",
    "    w_change = np.zeros(len(w))\n",
    "    for i in range(len(w) - 1):\n",
    "        if i != 0:\n",
    "            last_n = i-n\n",
    "            if last_n < 0:\n",
    "                w_change[i] = w[i] - np.mean(w[:i])\n",
    "                \n",
    "            else:\n",
    "                w_change[i] = w[i] - np.mean(w[last_n:i])\n",
    "\n",
    "\n",
    "\n",
    "    return w_change\n",
    "\n",
    "def create_trial_data(data_list, header, path, n_rows = 100):\n",
    "    ncols = len(header)\n",
    "    trial_matrix = np.zeros((n_rows, ncols))\n",
    "    counter = 0\n",
    "    for data in data_list:\n",
    "        for array in data:\n",
    "            trial_matrix[:, counter] = array\n",
    "            counter += 1\n",
    "\n",
    "    trial_df = pd.DataFrame(trial_matrix)\n",
    "    trial_df.to_csv(path, header=header)\n",
    "    \n",
    "    \n",
    "### Log likelihoods\n",
    "avg_ml_euc = np.mean(marginal_euc.reshape(48, 100), axis=0)\n",
    "avg_ml_euc[avg_ml_euc==0] = 0.00001  ## add epsilon to avoid numerical issues\n",
    "avg_ml_sr = np.mean(marginal_sr.reshape(48, 100), axis=0)\n",
    "avg_ml_sr[avg_ml_sr==0] = 0.00001\n",
    "nll_euc = -np.log(avg_ml_euc)\n",
    "nll_sr = -np.log(avg_ml_sr)\n",
    "\n",
    "\n",
    "## individual subjects\n",
    "marginal_euc[marginal_euc ==0] = 0.00001\n",
    "marginal_sr[marginal_sr ==0] = 0.00001\n",
    "nll_euc_ind = -np.log(marginal_euc)\n",
    "nll_sr_ind = - np.log(marginal_sr)\n",
    "\n",
    "\n",
    "nll_list = [nll_euc, nll_sr]\n",
    "nll_list_ind = [nll_euc_ind, nll_sr_ind]\n",
    "\n",
    "\n",
    "### RPEs\n",
    "sr_error = np.sqrt(np.mean(np.abs(SR_GP_RPE), axis=0))\n",
    "euc_error = np.sqrt(np.mean(np.abs(euc_GP_RPE), axis=0))\n",
    "\n",
    "rpe_list = [euc_error, sr_error]\n",
    "rpe_list_ind = [euc_GP_RPE.ravel(), SR_GP_RPE.ravel()]\n",
    "\n",
    "### Posterior\n",
    "\n",
    "comp_w2 = comp_w.reshape(48, 100)\n",
    "posterior = np.mean(comp_w2, axis=0) \n",
    "post_list = [posterior]\n",
    "post_list_ind = [comp_w]\n",
    "\n",
    "### Predictions\n",
    "\n",
    "\n",
    "avg_preds_euc = np.mean(euc_GP_preds_chosen, axis=0)\n",
    "avg_preds_sr = np.mean(SR_GP_preds_chosen, axis=0)\n",
    "preds_list = [avg_preds_euc, avg_preds_sr]\n",
    "preds_list_ind = [euc_GP_preds_chosen.ravel(), SR_GP_preds_chosen.ravel()]\n",
    "\n",
    "### Weights and deltas\n",
    "w_avg = np.mean(tbt_weights, axis=0)\n",
    "delta_w = w_delta_smooth(w_avg, 15)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "delta_w_ind = np.zeros((tbt_weights.shape[0], tbt_weights.shape[1]))\n",
    "for i, row in enumerate(tbt_weights):\n",
    "    delta_w_i = w_delta_smooth(row, 15)\n",
    "    delta_w_ind[i] = delta_w_i\n",
    "\n",
    "\n",
    "\n",
    "######## experimental\n",
    "###\n",
    "\n",
    "# euc_evidence = marginal_euc.reshape(48, 100)\n",
    "# sr_evidence = marginal_sr.reshape(48, 100)\n",
    "\n",
    "# euc_rel_evidence = -(-np.log(euc_evidence)) - (-np.log(sr_evidence))\n",
    "\n",
    "\n",
    "\n",
    "# idx_ = remove_outliers(np.mean(euc_rel_evidence, axis=0))\n",
    "# plt.scatter(np.mean(euc_rel_evidence, axis=0)[idx_][:-1], delta_w[idx_][1:])\n",
    "\n",
    "# scipy.stats.pearsonr(np.mean(euc_rel_evidence, axis=0)[idx_][:-1], delta_w[idx_][1:])\n",
    "# plt.show()\n",
    "\n",
    "# plt.scatter((nll_euc - nll_sr)[:-1], delta_w[1:])\n",
    "# scipy.stats.pearsonr((nll_euc - nll_sr)[:-1], delta_w[1:])\n",
    "# plt.show()\n",
    "# delta_corrs = np.zeros(48)\n",
    "\n",
    "# for i in range(len(delta_corrs)):\n",
    "#     delta_i = delta_w_ind[i]\n",
    "#     euc_ev_i = euc_ev_ind[i]\n",
    "#     idx = remove_outliers(euc_ev_i)\n",
    "# #    print(len(idx))\n",
    "#     euc_ev_i = euc_ev_i[idx]\n",
    "#     delta_i = delta_i[idx]\n",
    "    \n",
    "\n",
    "#     delta_corrs[i] = scipy.stats.pearsonr(euc_ev_i[1:], delta_i[:-1])[0]\n",
    "\n",
    "\n",
    "# plt.hist(delta_corrs)\n",
    "# plt.show()\n",
    "# scipy.stats.pearsonr(delta_corrs, m_rewards)\n",
    "#\n",
    "####\n",
    "### end experimental\n",
    "###################\n",
    "\n",
    "delta_w_ind = delta_w_ind.ravel()\n",
    "\n",
    "\n",
    "w_ind = tbt_weights.ravel()\n",
    "\n",
    "\n",
    "w_HP = np.array(per_trial_df[\"HP.euc.w\"])\n",
    "w_LP = np.array(per_trial_df[\"LP.euc.w\"])\n",
    "weight_list = [w_avg, w_HP, w_LP, delta_w]\n",
    "weight_list_ind = [w_ind, delta_w_ind]\n",
    "\n",
    "data_list = [nll_list, rpe_list, post_list, preds_list, weight_list]\n",
    "data_list_ind = [nll_list_ind, rpe_list_ind, post_list_ind, preds_list_ind, weight_list_ind]\n",
    "\n",
    "header = [\"nll_euc\", \"nll_temp\", \"RPE_euc\", \"RPE_temp\", \"posterior_euc\", \"pred_euc\", \"pred_temp\", \"weights_euc\", \"weights_high\", \"weights_low\", \"delta_w\"]\n",
    "\n",
    "header_ind = [\"nll_euc\", \"nll_temp\", \"RPE_euc\", \"RPE_temp\", \"posterior_euc\", \"pred_euc\", \"pred_temp\", \"weights_euc\", \"delta_w\"]\n",
    "\n",
    "## averaged over subjects\n",
    "if save_data:\n",
    "    create_trial_data(data_list, header, path= \"trial_data_models.csv\", n_rows=100)\n",
    "\n",
    "\n",
    "## individual\n",
    "if save_data:\n",
    "    create_trial_data(data_list_ind, header_ind, path=\"individual_trial_data_models.csv\", n_rows=4800)\n",
    "\n",
    "\n",
    "\n",
    "def plot_predictions(preds, truth, title=\"\", label=\"\"):\n",
    "    pred_mean = np.mean(preds, axis=0)\n",
    "    preds_sd = np.std(preds, axis=0)\n",
    "    plt.title(title)\n",
    "    plt.plot(np.arange(12),pred_mean, label=label)\n",
    "    plt.fill_between(np.arange(12), pred_mean + preds_sd, pred_mean - preds_sd , alpha=0.5)\n",
    "    plt.plot(np.arange(12), truth, label=\"Ground truth\")\n",
    "    plt.xlabel(\"Monster number\")\n",
    "    plt.xticks(np.arange(12))\n",
    "    plt.ylabel(\"Estimated value\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"figures/predicted values {label} {title}.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "subjects = np.unique(subj)\n",
    "\n",
    "def save_csv(matrix, indices, path):\n",
    "    matrix_df = pd.DataFrame(matrix)\n",
    "    matrix_df.index = indices\n",
    "    matrix_df.to_csv(path)\n",
    "\n",
    "\n",
    "if save_data:\n",
    "    Path(\"fmri/predictions\").mkdir(parents=True, exist_ok=True)\n",
    "    save_csv(SR_GP_preds_chosen, subjects, \"fmri/predictions/SR_GP_preds_chosen.csv\")\n",
    "    save_csv(SR_GP_preds_unchosen, subjects, \"fmri/predictions/SR_GP_preds_unchosen.csv\")\n",
    "    save_csv(SR_GP_RPE, subjects, \"fmri/predictions/SR_GP_RPE.csv\")\n",
    "\n",
    "    save_csv(euc_GP_preds_chosen, subjects, \"fmri/predictions/RBF_preds_chosen.csv\")\n",
    "    save_csv(euc_GP_preds_unchosen, subjects, \"fmri/predictions/RBF_preds_unchosen.csv\")\n",
    "    save_csv(euc_GP_RPE, subjects, \"fmri/predictions/RBF_RPE.csv\")\n",
    "\n",
    "    save_csv(rich_euc_GP_preds_chosen, subjects, \"fmri/predictions/rich_RBF_preds_chosen.csv\")\n",
    "    save_csv(rich_euc_GP_preds_unchosen, subjects, \"fmri/predictions/rich_RBF_preds_unchosen.csv\")\n",
    "    save_csv(rich_euc_GP_RPE, subjects, \"fmri/predictions/rich_RBF_RPE.csv\")\n",
    "\n",
    "\n",
    "    save_csv(comp_preds_chosen, subjects, \"fmri/predictions/comp_preds_chosen.csv\")\n",
    "    save_csv(comp_preds_unchosen, subjects, \"fmri/predictions/comp_preds_unchosen.csv\")\n",
    "    save_csv(comp_RPE, subjects, \"fmri/predictions/comp_RPE.csv\")\n",
    "\n",
    "    ## compositional predictions\n",
    "    save_csv(predicted_values_ctx1, subjects, \"fmri/predictions/comp_final_predictions1.csv\")\n",
    "    save_csv(predicted_values_ctx2, subjects, \"fmri/predictions/comp_final_predictions2.csv\")\n",
    "\n",
    "    ## euclidean predicitons\n",
    "    save_csv(euc_predicted_values_ctx1, subjects, \"fmri/predictions/euc_final_predictions1.csv\")\n",
    "    save_csv(euc_predicted_values_ctx2, subjects, \"fmri/predictions/euc_final_predictions2.csv\")\n",
    "    \n",
    "    ## temporal predictions\n",
    "    save_csv(sr_predicted_values_ctx1, subjects, \"fmri/predictions/temporal_final_predictions1.csv\")\n",
    "    save_csv(sr_predicted_values_ctx2, subjects, \"fmri/predictions/temporal_final_predictions2.csv\")\n",
    "\n",
    "    ## MT_predictions\n",
    "    save_csv(MT_predicted_values_ctx1, subjects, \"fmri/predictions/MT_final_predictions1.csv\")\n",
    "    save_csv(MT_predicted_values_ctx2, subjects, \"fmri/predictions/MT_final_predictions2.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
